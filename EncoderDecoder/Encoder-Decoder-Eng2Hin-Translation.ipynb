{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://www.kaggle.com/code/aiswaryaramachandran/english-to-hindi-neural-machine-translation/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Anaconda\\envs\\misc\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from string import digits, punctuation\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(127607, 3)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(r\"Data/Hindi_English_Truncated_Corpus.csv\")\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source\n",
       "tides        50000\n",
       "ted          39881\n",
       "indic2012    37726\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['source'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39881, 3)\n"
     ]
    }
   ],
   "source": [
    "ted_data = data[data[\"source\"] == \"ted\"]\n",
    "print(ted_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>hindi_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ted</td>\n",
       "      <td>politicians do not have permission to do what ...</td>\n",
       "      <td>राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ted</td>\n",
       "      <td>I'd like to tell you about one such child,</td>\n",
       "      <td>मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ted</td>\n",
       "      <td>what we really mean is that they're bad at not...</td>\n",
       "      <td>हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ted</td>\n",
       "      <td>And who are we to say, even, that they are wrong</td>\n",
       "      <td>और हम होते कौन हैं यह कहने भी वाले कि वे गलत हैं</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ted</td>\n",
       "      <td>So there is some sort of justice</td>\n",
       "      <td>तो वहाँ न्याय है</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ted</td>\n",
       "      <td>This changed slowly</td>\n",
       "      <td>धीरे धीरे ये सब बदला</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ted</td>\n",
       "      <td>were being produced.</td>\n",
       "      <td>उत्पन्न नहीं कि जाती थी.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ted</td>\n",
       "      <td>And you can see, this LED is going to glow.</td>\n",
       "      <td>और जैसा आप देख रहे है, ये एल.ई.डी. जल उठेगी।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ted</td>\n",
       "      <td>to turn on the lights or to bring him a glass ...</td>\n",
       "      <td>लाईट जलाने के लिए या उनके लिए पानी लाने के लिए,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ted</td>\n",
       "      <td>Can you imagine saying that?</td>\n",
       "      <td>क्या आप ये कल्पना कर सकते है</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   source                                   english_sentence  \\\n",
       "0     ted  politicians do not have permission to do what ...   \n",
       "1     ted         I'd like to tell you about one such child,   \n",
       "3     ted  what we really mean is that they're bad at not...   \n",
       "7     ted   And who are we to say, even, that they are wrong   \n",
       "13    ted                   So there is some sort of justice   \n",
       "23    ted                                This changed slowly   \n",
       "26    ted                               were being produced.   \n",
       "30    ted        And you can see, this LED is going to glow.   \n",
       "32    ted  to turn on the lights or to bring him a glass ...   \n",
       "35    ted                       Can you imagine saying that?   \n",
       "\n",
       "                                       hindi_sentence  \n",
       "0   राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...  \n",
       "1   मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...  \n",
       "3      हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते  \n",
       "7    और हम होते कौन हैं यह कहने भी वाले कि वे गलत हैं  \n",
       "13                                   तो वहाँ न्याय है  \n",
       "23                               धीरे धीरे ये सब बदला  \n",
       "26                           उत्पन्न नहीं कि जाती थी.  \n",
       "30       और जैसा आप देख रहे है, ये एल.ई.डी. जल उठेगी।  \n",
       "32    लाईट जलाने के लिए या उनके लिए पानी लाने के लिए,  \n",
       "35                       क्या आप ये कल्पना कर सकते है  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ted_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source              0\n",
       "english_sentence    0\n",
       "hindi_sentence      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for null values\n",
    "ted_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1078"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for duplicate values\n",
    "ted_data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Surbhit Kumar\\AppData\\Local\\Temp\\ipykernel_12352\\299429072.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ted_data.drop_duplicates(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#drop duplicates\n",
    "ted_data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "ted_sample = ted_data.sample(n=25000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert english and hindi sentences to lowercase\n",
    "ted_sample.english_sentence = ted_sample.english_sentence.apply(lambda x: x.lower())\n",
    "\n",
    "ted_sample.hindi_sentence = ted_sample.hindi_sentence.apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove quotes and replace with space\n",
    "ted_sample.english_sentence = ted_sample.english_sentence.apply(lambda x: re.sub(\"'\",\"\",x))\n",
    "\n",
    "ted_sample.hindi_sentence = ted_sample.hindi_sentence.apply(lambda x: re.sub(\"'\",\"\",x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove special characters and punctuations\n",
    "exclude_punc = set(punctuation)\n",
    "\n",
    "ted_sample.english_sentence = ted_sample.english_sentence.apply(lambda x: ''.join(ch for ch in x if ch not in exclude_punc))\n",
    "\n",
    "ted_sample.hindi_sentence = ted_sample.hindi_sentence.apply(lambda x: ''.join(ch for ch in x if ch not in exclude_punc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove numbers\n",
    "remove_digits = str.maketrans('','',digits)\n",
    "\n",
    "ted_sample.english_sentence = ted_sample.english_sentence.apply(lambda x: x.translate(remove_digits))\n",
    "\n",
    "ted_sample.hindi_sentence = ted_sample.hindi_sentence.apply(lambda x: x.translate(remove_digits))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove hindi digits\n",
    "ted_sample.hindi_sentence = ted_sample.hindi_sentence.apply(lambda x: re.sub(\"[२३०८१५७९४६]\",\"\",x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing extra spaces\n",
    "ted_sample.english_sentence = ted_sample.english_sentence.apply(lambda x: x.strip())\n",
    "\n",
    "ted_sample.hindi_sentence = ted_sample.hindi_sentence.apply(lambda x: x.strip())\n",
    "\n",
    "ted_sample.english_sentence = ted_sample.english_sentence.apply(lambda x: re.sub(\" +\",\" \",x))\n",
    "\n",
    "ted_sample.hindi_sentence = ted_sample.hindi_sentence.apply(lambda x: re.sub(\" +\",\" \",x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add START and END tokens to the target sequence\n",
    "\n",
    "ted_sample.hindi_sentence = ted_sample.hindi_sentence.apply(lambda x: \"START_ \"+x+\" _END\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get english and hindi vocabulary\n",
    "\n",
    "def get_all_words(data):\n",
    "    all_words = set()\n",
    "    for line in data:\n",
    "        for word in line.split():\n",
    "            if word not in all_words:\n",
    "                all_words.add(word)\n",
    "    \n",
    "    return all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English words: 14030\n",
      "Hindi words: 17540\n"
     ]
    }
   ],
   "source": [
    "all_eng_words = get_all_words(ted_sample.english_sentence)\n",
    "all_hin_words = get_all_words(ted_sample.hindi_sentence)\n",
    "\n",
    "print(f\"English words: {len(all_eng_words)}\")\n",
    "print(f\"Hindi words: {len(all_hin_words)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding length of english and hindi sentences\n",
    "ted_sample['len_english_sentence'] = ted_sample.english_sentence.apply(lambda x: len(x.split(\" \")))\n",
    "\n",
    "ted_sample['len_hindi_sentence'] = ted_sample.hindi_sentence.apply(lambda x: len(x.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length of input (english) sentence: 20\n",
      "Max length of output (hindi) sentence: 30\n"
     ]
    }
   ],
   "source": [
    "print(f\"Max length of input (english) sentence: {max(ted_sample['len_english_sentence'])}\")\n",
    "\n",
    "print(f\"Max length of output (hindi) sentence: {max(ted_sample['len_hindi_sentence'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keeping data with max 20 chars only\n",
    "ted_sample=ted_sample[ted_sample['len_english_sentence']<=20]\n",
    "\n",
    "ted_sample=ted_sample[ted_sample['len_hindi_sentence']<=20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing the vocab and its count for english and hindi sentences\n",
    "\n",
    "input_words = sorted(list(all_eng_words))\n",
    "\n",
    "target_words = sorted(list(all_hin_words))\n",
    "\n",
    "num_encoder_tokens = len(all_eng_words)\n",
    "\n",
    "num_decoder_tokens = len(all_hin_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length_src = max(ted_sample['len_english_sentence'])\n",
    "\n",
    "max_length_tar = max(ted_sample['len_hindi_sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n",
    "\n",
    "target_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n",
    "\n",
    "reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (19819,)\n",
      "Test: (4955,)\n"
     ]
    }
   ],
   "source": [
    "X, y = ted_sample['english_sentence'], ted_sample['hindi_sentence']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state=42)\n",
    "\n",
    "print(f\"Train: {X_train.shape}\")\n",
    "\n",
    "print(f\"Test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(X = X_train, y = y_train, batch_size = 128):\n",
    "    while True:\n",
    "        for j in range(0, len(X), batch_size):\n",
    "            encoder_input_data = np.zeros((batch_size, max_length_src),dtype='float32')\n",
    "            decoder_input_data = np.zeros((batch_size, max_length_tar),dtype='float32')\n",
    "            decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens),dtype='float32')\n",
    "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
    "                for t, word in enumerate(input_text.split()):\n",
    "                    encoder_input_data[i, t] = input_token_index[word] # encoder input seq\n",
    "                for t, word in enumerate(target_text.split()):\n",
    "                    if t<len(target_text.split())-1:\n",
    "                        decoder_input_data[i, t] = target_token_index[word] # decoder input seq\n",
    "                    if t>0:\n",
    "                        # decoder target sequence (one hot encoded)\n",
    "                        # does not include the START_ token\n",
    "                        # Offset by one timestep\n",
    "                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n",
    "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim=300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Anaconda\\envs\\misc\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoder_inputs = Input(shape=(None,))\n",
    "enc_emb =  Embedding(num_encoder_tokens, latent_dim, mask_zero = True)(encoder_inputs)\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "misc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
